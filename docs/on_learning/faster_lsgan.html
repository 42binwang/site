<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <script>
      (function() {
      var method;
      var methods = [
          'assert', 'clear', 'count', 'debug', 'dir', 'dirxml', 'error',
          'exception', 'group', 'groupCollapsed', 'groupEnd', 'info', 'log',
          'markTimeline', 'profile', 'profileEnd', 'table', 'time', 'timeEnd',
          'timeline', 'timelineEnd', 'timeStamp', 'trace', 'warn'
      ];
      var length = methods.length;
      var console = (window.console = window.console || {});
      while (length--) {
          method = methods[length];
          // Only stub undefined methods.
          if (!console[method]) {
              console[method] = function () {};
          }
      }
      }());
      
      
    </script>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="./../basic.css" rel="stylesheet" type="text/css">
    <link rel="shortcut icon" href="./../favicon.ico">
    <title>Fast LSGAN in Canton</title>
  </head>
  <body id="body">
    <div class="navigation_area">
      <div class="navnode">
              <div class="navnode_title">/</div>
              <div class="navnode"><a href="./../index.html">Index</a>
              </div>
              <div class="navnode"><a href="./../bio.html">About</a>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/lit</div>
                      <div class="navnode"><a href="./../lit/why_bad_idea.html">Why Smart People Have Bad Ideas</a>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/on_learning</div>
                      <div class="navnode"><a href="./../on_learning/gan.html">GAN 生成式对抗网络</a>
                      </div>
                      <div class="navnode"><a href="./../on_learning/course_resources.html">Learning Resources</a>
                      </div>
                      <div class="navnode"><a href="./../on_learning/faster_lsgan.html">Fast LSGAN in Canton</a>
                      </div>
                      <div class="navnode"><a href="./../on_learning/fast_gan_in_keras.html"> Fast DCGAN in Keras</a>
                      </div>
                      <div class="navnode"><a href="./../on_learning/artist.html">Training of Artists</a>
                      </div>
                      <div class="navnode"><a href="./../on_learning/gd.html">Gradient Descent 梯度下降法</a>
                      </div>
                      <div class="navnode"><a href="./../on_learning/how_to.html">Baby steps for ML</a>
                      </div>
                      <div class="navnode"><a href="./../on_learning/resnet_keras.html">Residual Network in Keras</a>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/audio</div>
                              <div class="navnode"><a href="./../on_learning/audio/wavenet_arch.html"> Behind WaveNet</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/image</div>
                              <div class="navnode"><a href="./../on_learning/image/style_transfer.html">On Style Transfer 风格转移</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/motor_model</div>
                              <div class="navnode"><a href="./../on_learning/motor_model/motor.html">Learn models of motors</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/activations</div>
                              <div class="navnode"><a href="./../on_learning/activations/index.html">Activation Functions</a>
                              </div>
                              <div class="navnode"><a href="./../on_learning/activations/relu.html">Rectified Linear Unit 整流线性单元</a>
                              </div>
                      </div>
                      <div class="navnode">
                              <div class="navnode_title">/on_learning/rl</div>
                              <div class="navnode"><a href="./../on_learning/rl/ddpg.html">DDPG Method</a>
                              </div>
                              <div class="navnode"><a href="./../on_learning/rl/rl.html">RL is progressing rapidly</a>
                              </div>
                      </div>
              </div>
              <div class="navnode">
                      <div class="navnode_title">/on_life</div>
                      <div class="navnode"><a href="./../on_life/electrical.html">Power System Analysis</a>
                      </div>
                      <div class="navnode"><a href="./../on_life/numjs.html">NumJs</a>
                      </div>
              </div>
      </div>
    </div>
    <div class="markdown_content"><h1 data-sourcepos="3:1-3:35">Fast LSGAN in Canton (TensorFlow)</h1>
<p data-sourcepos="5:1-5:103">LSGAN(<a href="https://arxiv.org/pdf/1611.04076v2.pdf">https://arxiv.org/pdf/1611.04076v2.pdf</a>) is basically DCGAN with MSE loss. (LS for Least Square)</p>
<p data-sourcepos="7:1-7:178">In DCGAN we use sigmoid + cross entropy, so gradients could vanish, which might not be good for learning. In LSGAN the author removed sigmoid and replaced cross entropy with MSE.</p>
<pre><code data-sourcepos="9:1-22:37" class="language-py">generated = g(noise)
gscore = d(generated)
rscore = d(real_data)

# original DCGAN(with single side label smoothing)
dloss = - (log_eps(1-gscore) + .1 * log_eps(1-rscore)+ .9 * log_eps(rscore))
gloss = - log_eps(gscore)

# LSGAN
# note: remove the sigmoid from the discriminator
dloss = tf.reduce_mean((gscore-0)**2 + (rscore-1)**2)
gloss = tf.reduce_mean((gscore-1)**2)
</code></pre>
<p data-sourcepos="24:1-24:97">the code is available at <a href="https://github.com/ctmakro/hellotensor/blob/master/lets_gan_canton.py">https://github.com/ctmakro/hellotensor/blob/master/lets_gan_canton.py</a>.</p>
<p data-sourcepos="26:1-26:122">You should use the same Adam setting as in DCGAN (I use <code>lr=1e-4, beta1=0.5</code>), otherwise the whole thing may not converge.</p>
<p data-sourcepos="28:1-28:7">result:</p>
<p data-sourcepos="30:1-30:75">(this was from a higher parameter count model, after ~40000 x 32 examples):</p>
<p data-sourcepos="32:1-32:23"><img src="lsgan_training.png" alt="" /></p>
<p data-sourcepos="34:1-34:186">after convergence i think it would be boring just producing a minibatch of 32x32 images and post it here, so i increased the size of the input to the generator, generating large patches:</p>
<p data-sourcepos="36:1-36:61">(from lower parameter count model, after ~20000 x 32 exampes)</p>
<h2 data-sourcepos="40:1-40:8">Notes</h2>
<ol data-sourcepos="42:1-87:0">
<li data-sourcepos="42:1-65:0">
<p data-sourcepos="42:4-42:380">Please Do Use batch discrimination (within one minibatch, calculate each sample's distance to other samples, then provide that distance as a feature map to next conv layer). The earlier version of my code includes a not-very-good implementation that prevents generator from generating a full batch of identical samples, but won't work if only some of the samples are identical.</p>
<p data-sourcepos="44:5-44:198">according to <a href="https://arxiv.org/abs/1606.03498">https://arxiv.org/abs/1606.03498</a>, their batch discriminator consist of a trainable tensor, by multiplying input batch with that tensor you get a vector of discriminating features.</p>
<p data-sourcepos="46:5-46:88">Instead I simply calculate the L1 diff between tensors, then apply exp(- abs_diff) :</p>
<pre><code data-sourcepos="48:5-62:18" class="language-py">def batch_disc(i):
    #assume i shape [N H W C]
    s = tf.shape(i)
    NHWC1 = tf.expand_dims(i,4)
    AHWCN = tf.expand_dims(tf.transpose(i,[1,2,3,0]),0)
    diffs = NHWC1 - AHWCN # [N H W C N]
    abs_diffs = tf.abs(diffs)
    # shape [N H W C N]
    feat = tf.reduce_mean(tf.exp(-abs_diffs), [3,4])#[N H W]
    feat = tf.expand_dims(feat,3)
    # shape [N H W 1]
    out = tf.concat([i, feat],axis=-1) # [N H W C+1]
    return out
</code></pre>
<p data-sourcepos="64:5-64:118">batch discrimination is very, very important. you can learn more tricks on Ferenc's site <a href="http://www.inference.vc">http://www.inference.vc</a></p>
</li>
<li data-sourcepos="66:1-82:0">
<p data-sourcepos="66:4-66:17">Instance Noise</p>
<p data-sourcepos="68:5-68:107">add noise to both the generator output and the real images, before feeding them into the discriminator.</p>
<pre><code data-sourcepos="70:5-80:32" class="language-py">inl = tf.Variable(1.)

def noisy(i):
    return i + tf.random_normal(mean=0,stddev=inl,shape=tf.shape(i))

generated = g(noise)

gscore = d(noisy(generated))
rscore = d(noisy(real_data))
</code></pre>
<p data-sourcepos="81:5-81:417">then decrease it overtime. This technique blurs the border between the distributions of the generated examples and the real ones, making it harder for the discriminator, and easier for the generator. due to the noise, the discriminator cannot use details to discriminate between real and fake examples, therefore it wont force the generator to generate details (that could lead to mode collapse) in the beginning.</p>
</li>
<li data-sourcepos="83:1-87:0">
<p data-sourcepos="83:4-83:18">too much tricks</p>
<p data-sourcepos="85:5-85:114">to get results like those in goodfellow's paper, you have to try all his tricks. I don't have time for that...</p>
</li>
</ol>
<h2 data-sourcepos="88:1-88:40">Notes on deconv (or conv2d_transpose)</h2>
<p data-sourcepos="90:1-90:46">The DCGAN work uses deconv to upsample images.</p>
<ol data-sourcepos="92:1-94:0">
<li data-sourcepos="92:1-92:56">inconvenient (you have to set output shapes manually)</li>
<li data-sourcepos="93:1-94:0">produce tiling artifacts</li>
</ol>
<p data-sourcepos="95:1-95:102">instead we use nearest neighbour upsampling, offered in <code>canton</code> as <code>ct.Up2D()</code>, followed by a conv2d.</p>
<p data-sourcepos="97:1-97:36">here's our Generator implementation:</p>
<pre><code data-sourcepos="99:1-121:12" class="language-py">def gen_gen():
    c = Can()
    def deconv(nip,nop,tail=True,upscale=2):
        dc = Can()
        dc.add(Up2D(upscale))
        dc.add(Conv2D(nip,nop,k=4,std=1,usebias=not tail))
        if tail:
            dc.add(BatchNorm(nop))
            dc.add(Act('relu'))
        dc.chain()
        return dc

    ngf = 32
    c.add(deconv(zed,ngf*8,upscale=4)) #4
    c.add(deconv(ngf*8,ngf*4))
    c.add(deconv(ngf*4,ngf*2))
    c.add(deconv(ngf*2,ngf*1)) #32
    c.add(deconv(ngf*1,3,tail=False,upscale=1))
    c.add(Act('tanh'))
    c.chain()
    return c
</code></pre>
<p data-sourcepos="123:1-123:237">The generated quality is better than using deconv. No checkboard, yet banding still. For best upsampling performance, you should consider ESPCN (<a href="http://www.inference.vc/holiday-special-deriving-the-subpixel-cnn-from-first-principles/">http://www.inference.vc/holiday-special-deriving-the-subpixel-cnn-from-first-principles/</a>).</p>
<h2 data-sourcepos="125:1-125:17">What is Canton</h2>
<p data-sourcepos="127:1-127:175">A lightweight wrapper around TensorFlow. It offers convenience of Keras but never get into your way. It's also much faster at construction because it doesn't check the shapes.</p>
<p data-sourcepos="129:1-129:54">you may fork canton on GitHub or <code>pip install canton</code>.</p>
</div>
    <div class="meta_string">
      <p>file: faster_lsgan.md</p>
      <p>last modified: 2017-03-04 00:35</p>
    </div>
    <script>
      //if(window.HighlightEverything){window.HighlightEverything()}
      
    </script>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/atom-one-light.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>
    <script>
      hljs.initHighlightingOnLoad();
      
    </script>
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
  </body>
</html>